{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import get_dataloader\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'COVID19CTS224/S224/'\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loader_train, loader_val, loader_test = get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19800aae410>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def get_model(model_name='resnet18', pretrained=False):\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "    else:\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "model = get_model('resnet18', pretrained=False).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view(-1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.4577, Train Acc: 0.7957\n",
      "  Val Loss:   0.6912, Val Acc:   0.7000\n",
      "Epoch 2/10:\n",
      "  Train Loss: 0.2995, Train Acc: 0.8759\n",
      "  Val Loss:   0.6199, Val Acc:   0.8500\n",
      "Epoch 3/10:\n",
      "  Train Loss: 0.2948, Train Acc: 0.8759\n",
      "  Val Loss:   0.6497, Val Acc:   0.7500\n",
      "Epoch 4/10:\n",
      "  Train Loss: 0.2388, Train Acc: 0.9006\n",
      "  Val Loss:   3.2005, Val Acc:   0.5833\n",
      "Epoch 5/10:\n",
      "  Train Loss: 0.1914, Train Acc: 0.9219\n",
      "  Val Loss:   1.1179, Val Acc:   0.5667\n",
      "Epoch 6/10:\n",
      "  Train Loss: 0.1704, Train Acc: 0.9377\n",
      "  Val Loss:   1.2764, Val Acc:   0.7333\n",
      "Epoch 7/10:\n",
      "  Train Loss: 0.1882, Train Acc: 0.9233\n",
      "  Val Loss:   0.5841, Val Acc:   0.8667\n",
      "Epoch 8/10:\n",
      "  Train Loss: 0.1196, Train Acc: 0.9540\n",
      "  Val Loss:   0.3260, Val Acc:   0.9167\n",
      "Epoch 9/10:\n",
      "  Train Loss: 0.1075, Train Acc: 0.9575\n",
      "  Val Loss:   0.4536, Val Acc:   0.9000\n",
      "Epoch 10/10:\n",
      "  Train Loss: 0.0956, Train Acc: 0.9639\n",
      "  Val Loss:   0.9052, Val Acc:   0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_27848\\1410754545.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.75%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    train_loss, train_acc = train_model(model, loader_train, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_model(model, loader_val, criterion)\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# Load best model and evaluate on test\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "test_loss, test_acc = evaluate_model(model, loader_test, criterion)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training from Scratch ====\n",
      "Epoch 1/10\n",
      "Train Loss: 0.4576, Train Acc: 0.8027\n",
      "Val Loss: 1.7228, Val Acc: 0.5667\n",
      "Epoch 2/10\n",
      "Train Loss: 0.3048, Train Acc: 0.8783\n",
      "Val Loss: 0.7015, Val Acc: 0.6833\n",
      "Epoch 3/10\n",
      "Train Loss: 0.3014, Train Acc: 0.8749\n",
      "Val Loss: 0.4543, Val Acc: 0.7667\n",
      "Epoch 4/10\n",
      "Train Loss: 0.2557, Train Acc: 0.8976\n",
      "Val Loss: 0.4183, Val Acc: 0.8667\n",
      "Epoch 5/10\n",
      "Train Loss: 0.2540, Train Acc: 0.8922\n",
      "Val Loss: 1.0038, Val Acc: 0.6333\n",
      "Epoch 6/10\n",
      "Train Loss: 0.1986, Train Acc: 0.9228\n",
      "Val Loss: 4.2517, Val Acc: 0.5000\n",
      "Epoch 7/10\n",
      "Train Loss: 0.1611, Train Acc: 0.9367\n",
      "Val Loss: 0.3003, Val Acc: 0.9167\n",
      "Epoch 8/10\n",
      "Train Loss: 0.1305, Train Acc: 0.9496\n",
      "Val Loss: 0.2324, Val Acc: 0.9333\n",
      "Epoch 9/10\n",
      "Train Loss: 0.1095, Train Acc: 0.9590\n",
      "Val Loss: 0.5351, Val Acc: 0.8333\n",
      "Epoch 10/10\n",
      "Train Loss: 0.1172, Train Acc: 0.9604\n",
      "Val Loss: 0.3617, Val Acc: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_27848\\950816935.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_scratch.load_state_dict(torch.load(\"model_scratch_best.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Scratch): 91.50%\n"
     ]
    }
   ],
   "source": [
    "model_scratch = get_model('resnet18', pretrained=False).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_scratch.parameters(), lr=lr)\n",
    "\n",
    "print(\"==== Training from Scratch ====\")\n",
    "best_val_acc_scratch = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_acc = train_model(model_scratch, loader_train, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_model(model_scratch, loader_val, criterion)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    if val_acc > best_val_acc_scratch:\n",
    "        best_val_acc_scratch = val_acc\n",
    "        torch.save(model_scratch.state_dict(), \"model_scratch_best.pth\")\n",
    "\n",
    "model_scratch.load_state_dict(torch.load(\"model_scratch_best.pth\"))\n",
    "test_loss_scratch, test_acc_scratch = evaluate_model(model_scratch, loader_test, criterion)\n",
    "print(f\"Test Accuracy (Scratch): {test_acc_scratch*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training with Transfer Learning ====\n",
      "Epoch 1/10\n",
      "Train Loss: 0.3295, Train Acc: 0.8694\n",
      "Val Loss: 0.2765, Val Acc: 0.8833\n",
      "Epoch 2/10\n",
      "Train Loss: 0.1337, Train Acc: 0.9456\n",
      "Val Loss: 4.3701, Val Acc: 0.6333\n",
      "Epoch 3/10\n",
      "Train Loss: 0.1274, Train Acc: 0.9481\n",
      "Val Loss: 0.2163, Val Acc: 0.9333\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0806, Train Acc: 0.9718\n",
      "Val Loss: 0.6702, Val Acc: 0.8667\n",
      "Epoch 5/10\n",
      "Train Loss: 0.1110, Train Acc: 0.9604\n",
      "Val Loss: 0.2214, Val Acc: 0.9667\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0619, Train Acc: 0.9787\n",
      "Val Loss: 0.0356, Val Acc: 1.0000\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0337, Train Acc: 0.9921\n",
      "Val Loss: 0.6045, Val Acc: 0.8500\n",
      "Epoch 8/10\n",
      "Train Loss: 0.1535, Train Acc: 0.9416\n",
      "Val Loss: 1.0786, Val Acc: 0.7667\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0596, Train Acc: 0.9862\n",
      "Val Loss: 0.8082, Val Acc: 0.6833\n",
      "Epoch 10/10\n",
      "Train Loss: 0.1384, Train Acc: 0.9515\n",
      "Val Loss: 0.7605, Val Acc: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_27848\\1440805576.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_transfer.load_state_dict(torch.load(\"model_transfer_best.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Transfer): 97.25%\n"
     ]
    }
   ],
   "source": [
    "model_transfer = get_model('resnet18', pretrained=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_transfer.parameters(), lr=lr)\n",
    "\n",
    "print(\"==== Training with Transfer Learning ====\")\n",
    "best_val_acc_transfer = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_acc = train_model(model_transfer, loader_train, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_model(model_transfer, loader_val, criterion)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    if val_acc > best_val_acc_transfer:\n",
    "        best_val_acc_transfer = val_acc\n",
    "        torch.save(model_transfer.state_dict(), \"model_transfer_best.pth\")\n",
    "\n",
    "model_transfer.load_state_dict(torch.load(\"model_transfer_best.pth\"))\n",
    "test_loss_transfer, test_acc_transfer = evaluate_model(model_transfer, loader_test, criterion)\n",
    "print(f\"Test Accuracy (Transfer): {test_acc_transfer*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CAM visualizations for Scratch model...\n",
      "Generating CAM visualizations for Transfer model...\n"
     ]
    }
   ],
   "source": [
    "test_csv_path = 'COVID19CTS224/S224/test.csv'\n",
    "test_data = pd.read_csv(test_csv_path)\n",
    "class_names = test_data['label'].unique()\n",
    "base_path = 'COVID19CTS224/S224/'\n",
    "\n",
    "covid_images = []\n",
    "noncovid_images = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    images_in_class = test_data['filename'][test_data['label'] == class_name].tolist()\n",
    "    if class_name == '1':\n",
    "        covid_images.extend([os.path.join(base_path, img) for img in images_in_class])\n",
    "    else:\n",
    "        noncovid_images.extend([os.path.join(base_path, img) for img in images_in_class])\n",
    "\n",
    "random.shuffle(covid_images)\n",
    "random.shuffle(noncovid_images)\n",
    "\n",
    "selected_covid = covid_images[:10]\n",
    "selected_noncovid = noncovid_images[:10]\n",
    "selected_images = selected_covid + selected_noncovid\n",
    "\n",
    "# Prepare CAMs\n",
    "target_layers = [model_scratch.layer4[-1]]  # last convolutional layer for ResNet18\n",
    "cam_methods = {\n",
    "    'gradcam': GradCAM(model=model_scratch, target_layers=target_layers, reshape_transform=None),\n",
    "    'eigencam': EigenCAM(model=model_scratch, target_layers=target_layers, reshape_transform=None)\n",
    "}\n",
    "\n",
    "def apply_cam(image_path, model, cam_method):\n",
    "    rgb_img = np.array(Image.open(image_path).convert('RGB'))\n",
    "    rgb_img = np.float32(rgb_img) / 255.0\n",
    "    input_tensor = preprocess_image(rgb_img, mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # Forward pass to get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prediction = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    grayscale_cam = cam_method(input_tensor=input_tensor, targets=[ClassifierOutputTarget(prediction)])\n",
    "    # grayscale_cam is [N, H, W], here N=1\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam[0,:], use_rgb=True)\n",
    "    return visualization, prediction\n",
    "\n",
    "# Create directories to save CAM images\n",
    "os.makedirs(\"cam_results_scratch\", exist_ok=True)\n",
    "os.makedirs(\"cam_results_transfer\", exist_ok=True)\n",
    "\n",
    "# Visualize using both methods for both models\n",
    "# We'll do this for the from-scratch model first\n",
    "print(\"Generating CAM visualizations for Scratch model...\")\n",
    "for i, img_path in enumerate(selected_images):\n",
    "    for method_name, cam_method in cam_methods.items():\n",
    "        visualization, pred_class = apply_cam(img_path, model_scratch, cam_method)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.title(f\"{method_name.upper()} - Pred: {class_names[pred_class]}\")\n",
    "        plt.imshow(visualization)\n",
    "        plt.axis('off')\n",
    "        fname = f\"scratch_{method_name}_img{i}.png\"\n",
    "        plt.savefig(os.path.join(\"cam_results_scratch\", fname))\n",
    "        plt.close()\n",
    "\n",
    "# For the transfer model, we just change the model in CAM methods\n",
    "target_layers_transfer = [model_transfer.layer4[-1]]\n",
    "cam_methods_transfer = {\n",
    "    'gradcam': GradCAM(model=model_transfer, target_layers=target_layers_transfer, reshape_transform=None),\n",
    "    'eigencam': EigenCAM(model=model_transfer, target_layers=target_layers_transfer, reshape_transform=None)\n",
    "}\n",
    "\n",
    "print(\"Generating CAM visualizations for Transfer model...\")\n",
    "for i, img_path in enumerate(selected_images):\n",
    "    for method_name, cam_method in cam_methods_transfer.items():\n",
    "        visualization, pred_class = apply_cam(img_path, model_transfer, cam_method)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.title(f\"{method_name.upper()} - Pred: {class_names[pred_class]}\")\n",
    "        plt.imshow(visualization)\n",
    "        plt.axis('off')\n",
    "        fname = f\"transfer_{method_name}_img{i}.png\"\n",
    "        plt.savefig(os.path.join(\"cam_results_transfer\", fname))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Discussion\n",
    "\n",
    "Transfer learning can provide several benefits over training from scratch, especially when dealing with limited training data or complex tasks. In this scenario, using a pre-trained ResNet model that has already learned rich feature representations from a large and diverse dataset (such as ImageNet) can significantly speed up the convergence and improve the final accuracy. \n",
    "\n",
    "When we train from scratch, the model starts with random weights and must learn all relevant low-level and high-level features directly from our COVID CT dataset. This often requires more data and epochs to achieve comparable performance. If our dataset is small or less diverse, the model might fail to generalize well and underperform.\n",
    "\n",
    "On the other hand, transfer learning starts from a model that already has a good understanding of generic features (edges, textures, shapes). Therefore, it only needs to fine-tune these features to our specific task of identifying COVID vs Non-COVID CT images. Typically, we see faster convergence, reduced training time, and potentially higher final accuracy, as shown in the test results.\n",
    "\n",
    "In conclusion, transfer learning usually brings extra benefits over training from scratch by leveraging previously learned representations, leading to improved generalization and performance in fewer training iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
